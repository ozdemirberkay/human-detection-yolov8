{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.53 ðŸš€ Python-3.11.2 torch-2.5.1 CPU (Apple M1 Pro)\n",
      "Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'model.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 5, 2100) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.18.0...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.11M/1.11M [00:00<00:00, 3.30MB/s]\n",
      "Unzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /Users/berkay/Desktop/YuÌˆksek Lisans/model/calibration_image_sample_data_20x128x128x3_float32.npy...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 100.29file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.45...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 0.8s, saved as 'model.onnx' (11.6 MB)\n",
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.22.3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734935445.064305 13237850 devices.cc:76] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734935445.065219 13237850 single_machine.cc:361] Starting new session\n",
      "W0000 00:00:1734935445.421228 13237850 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1734935445.421242 13237850 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "I0000 00:00:1734935445.851507 13237850 devices.cc:76] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "I0000 00:00:1734935445.851580 13237850 single_machine.cc:361] Starting new session\n",
      "W0000 00:00:1734935446.148473 13237850 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1734935446.148493 13237850 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 7.8s, saved as 'model_saved_model' (29.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.18.0...\n",
      "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'model_saved_model/model_float32.tflite' (11.6 MB)\n",
      "\n",
      "Export complete (7.9s)\n",
      "Results saved to \u001b[1m/Users/berkay/Desktop/YuÌˆksek Lisans/model\u001b[0m\n",
      "Predict:         yolo predict task=detect model=model_saved_model/model_float32.tflite imgsz=320  \n",
      "Validate:        yolo val task=detect model=model_saved_model/model_float32.tflite imgsz=320 data=data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model_saved_model/model_float32.tflite'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.export(format=\"tflite\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
